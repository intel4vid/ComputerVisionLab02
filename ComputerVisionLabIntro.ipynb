{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ComputerVisionLab02 Intro\n",
    "\n",
    "The goal of this lab is to show the importance of visual datasets when building a machine learning model. Furthermore this lab will introduce you with the steps you need to follow to build and deploy a machine learning model within a production environment. \n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/VisualDataML.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/KeyFactorsML.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/ImportanceBigData.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/ModelML.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/DeepLearning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/MLCategories.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/AlgorithmsML.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/RepresentingML.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "Keras is a model-level library, providing high-level building blocks for developing deep learning models. It does not handle low-level operations such as tensor products, convolutions and so on itself. \n",
    "<img src=\"https://keras.io/img/keras-logo-small.jpg\" width=\"140\">\n",
    "\n",
    "Keras development is backed primarily by Google, and the Keras API comes packaged in TensorFlow as tf.keras. Additionally, Microsoft maintains the CNTK Keras backend. Amazon AWS is maintaining the Keras fork with MXNet support. Other contributing companies include NVIDIA, Uber, and Apple (with CoreML).\n",
    "\n",
    "<img src=\"./images/KerasStack.png\">\n",
    "\n",
    "\n",
    "## Keras backend\n",
    "Keras relies on a specialized, well optimized tensor manipulation library to do so, serving as the \"backend engine\" of Keras. Rather than picking one single tensor library and making the implementation of Keras tied to that library, Keras handles the problem in a modular way, and several different backend engines can be plugged seamlessly into Keras.\n",
    "\n",
    "At this time, Keras has three backend implementations available: the TensorFlow backend, the Theano backend, and the CNTK backend.\n",
    "\n",
    "* [TensorFlow](https://www.tensorflow.org/lite) is an open-source symbolic tensor manipulation framework developed by Google.\n",
    "* [Theano](http://deeplearning.net/software/theano/) is an open-source symbolic tensor manipulation framework developed by LISA Lab at Université de Montréal.Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. The latest release of Theano was on 2017/11/15. \n",
    "* [CNTK](https://docs.microsoft.com/en-us/cognitive-toolkit/) is an open-source toolkit for deep learning developed by Microsoft. It describes neural networks as a series of computational steps via a directed graph. CNTK allows the user to easily realize and combine popular model types such as feed-forward DNNs, convolutional neural networks (CNNs) and recurrent neural networks (RNNs/LSTMs). CNTK implements stochastic gradient descent (SGD, error backpropagation) learning with automatic differentiation and parallelization across multiple GPUs and servers.<br><br><br><br>\n",
    "\n",
    "\n",
    "## Keras popularity\n",
    "\n",
    "<img src=\"./images/KerasPop01.png\" width=\"600\">\n",
    "<br><br>\n",
    "<img src=\"./images/KerasPop02.png\" width=\"600\">\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Keras Ecosystem\n",
    "\n",
    "* ### [Keras Tuner](https://keras-team.github.io/keras-tuner/)\n",
    "scalable hyperparameter search framework\n",
    "* ### [AutoKeras](https://autokeras.com/)\n",
    "widely accessible and easy to learn and use machine learning AutoML system based on Keras\n",
    "* ### [TensorFlow Cloud](https://github.com/tensorflow/cloud)\n",
    "set of utilities for running large-scale Keras training jobs on Google Cloud Platform\n",
    "* ### [TensorFlow.js](https://www.tensorflow.org/js)\n",
    "used for running TF models in the browser or on a Node.js server\n",
    "* ### [TensorFlow Lite](https://www.tensorflow.org/lite) \n",
    "open source deep learning framework for deploying ML models on mobile and IoT devices\n",
    "* ### [Model optimization toolkit](https://www.tensorflow.org/model_optimization)\n",
    "toolkit is used to make ML models faster and more memory and power efficient\n",
    "* ### [TFX integration](https://www.tensorflow.org/tfx) \n",
    "ML platform for deploying and maintaining production machine learning pipelines\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interoperability and Compatibility\n",
    "Keras also supports the [ONNX](https://onnx.ai/) format. \n",
    "\n",
    "<img src=\"https://onnx.ai/assets/mlogo.png\" width=\"140\">\n",
    "\n",
    "ONNX is a open format to represent deep learning models. With ONNX, AI developers can more easily move models between state-of-the-art tools and choose the combination that is best for them. ONNX is developed and supported by a community of partners.\n",
    "\n",
    "<img src=\"./images/ONNXCommunity.png\">\n",
    "\n",
    "The keras2onnx model converter enables users to convert Keras models into the ONNX model format. Initially, the Keras converter was developed in the project onnxmltools. To support more kinds of Keras models and reduce the complexity of mixing multiple converters, keras2onnx was created to convert the Keras model only.\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to end ML model requirements\n",
    "\n",
    "#### 1. Acquiring/Creating a dataset \n",
    "#### 2. Preparing a dataset\n",
    "#### 3. Dataset split to train and test data\n",
    "#### 4. Training the ML model\n",
    "#### 5. The ML model validation\n",
    "#### 6. ML deployment\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [CIFAR-10/100](https://www.cs.toronto.edu/~kriz/cifar.html) dataset\n",
    "Dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "<img src=\"./images/CIFAR.png\" width=\"500\">\n",
    "\n",
    "### 2. [MNIST](http://yann.lecun.com/exdb/mnist/) Dataset\n",
    "The MNIST database has a training set of 60,000 examples, and a test set of 10,000 examples. \n",
    "<img src=\"./images/MNIST.png\" width=\"500\">\n",
    "\n",
    "### 3. IMDB-Wiki Dataset\n",
    "Dataset has 520k images - gender and age prediction.\n",
    "<img src=\"./images/IMDB.png\" width=\"500\">\n",
    "\n",
    "### 4. [ImageNet](http://www.image-net.org/challenges/LSVRC/) dataset\n",
    "Evaluation of object detection and image classification algorithms.\n",
    "<img src=\"./images/imagenet.jpeg\" width=\"500\">\n",
    "\n",
    "### 5. Places2 Database dataset\n",
    "Dateaset has more than 10 million images and over 400 scenes. It is used for scene classification and scene parsing.\n",
    "<img src=\"./images/Places.png\" width=\"500\">\n",
    "\n",
    "### 6. [COCO](http://cocodataset.org/#external) dataset\n",
    "A large-scale object detection, segmentation, and captioning dataset with several features including Object segmentation, Recognition in context, Superpixel stuff segmentation, 330K images (>200K labeled), 1.5 million object instances, 80 object categories, 91 stuff categories, 5 captions per image, 250,000 people with keypoints.\n",
    "<img src=\"./images/COCO.png\" width=\"500\">\n",
    "\n",
    "### 7. [Kaggle Datasets Collection](https://www.kaggle.com/datasets) \n",
    "Kaggle enables you to search among 36924 datasets. \n",
    "<img src=\"./images/KaggleData.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring Datasets using [googleimagesdownload](https://pypi.org/project/google_images_download/2.3.0/) or [flickerimagesdownloader](https://github.com/ultralytics/flickr_scraper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. googleimagesdownload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Searching for images and downloading them to create your ML dataset can be performed using [googleimagesdownload](https://pypi.org/project/google_images_download/2.3.0/). Before we start using the library we need to download it and install. This can be done using pip as shown below. Take care about the dependencies (pip install requests-futures, pip install pandas, pip install bs4, pip install requests)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install googleimagedownloader"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second prerequisite that has to be met is downloading of [Chromedriver](https://sites.google.com/a/chromium.org/chromedriver/home). In order to get **googleimagedonwloader** working the downloaded version of Chromedriver has to be the same as the version of the Chrome browser installed on your PC.  \n",
    "Additionally, you can download images through CLI interface or from a python file or jupyter notebook "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\AIclass\\\\ComputerVisionLab02'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item no.: 1 --> Item name = bear\n",
      "Evaluating...\n",
      "Starting Download...\n",
      "\n",
      "\n",
      "Unfortunately all 10 could not be downloaded because some images were not downloadable. 0 is all we got for this search filter!\n",
      "\n",
      "Errors: 0\n",
      "\n",
      "\n",
      "Everything downloaded!\n",
      "Total errors: 0\n",
      "Total time taken: 2.3350934982299805 Seconds\n"
     ]
    }
   ],
   "source": [
    "!googleimagesdownload -k \"polar bear\" -l 10 -o dataset/train -i polar -cd \"./drivers/chromedriver.exe\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. flickerimagesdownloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10 https://live.staticflickr.com/65535/48620326787_f87bafc371_o.jpg\n",
      "1/10 https://live.staticflickr.com/65535/48129479887_01a6ef34b9_o.jpg\n",
      "2/10 https://farm3.staticflickr.com/2850/33242579343_62e21599f2_b.jpg\n",
      "3/10 https://live.staticflickr.com/1650/25826570813_9275af2eb2_o.jpg\n",
      "4/10 https://farm4.staticflickr.com/3233/3359914159_de6e521fe0_b.jpg\n",
      "5/10 https://farm4.staticflickr.com/3445/3359918993_d7dd1d4916_b.jpg\n",
      "6/10 https://live.staticflickr.com/4469/36897146383_1827dc68ae_o.jpg\n",
      "7/10 https://farm66.staticflickr.com/65535/49001595021_3730a6df28_b.jpg\n",
      "8/10 https://live.staticflickr.com/4571/37795143414_8ccae77768_o.jpg\n",
      "9/10 https://live.staticflickr.com/917/42416468264_e803e9c54b_o.jpg\n",
      "Done. (0.8s)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'on' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'flowers'' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!python ./flickr_scraper_master/flickr_scraper.py --search 'honeybees&on&flowers' --n 10 --download"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Datasets in Cloud environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example how image dataset was created within a cloud environment to detect objects in images. In this example GCP - [Google Cloud Platform Vision module](https://console.cloud.google.com/vision/datasets?project=tvdetection01) was used to upload, store, create, label, train, validate and export ML model to mobile, web or containerized platforms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
