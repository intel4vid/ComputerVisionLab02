{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ComputerVisionLab02 Intro\n",
    "\n",
    "The goal of this lab is to show the importance of visual datasets when building a machine learning model. Furthermore this lab will introduce you with the basic building blocks of ML model based on Convolutional Neural Networks. \n",
    "\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/VisualDataML.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/KeyFactorsML.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/ImportanceBigData.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/ModelML.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/DeepLearning.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/MLCategories.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/AlgorithmsML.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./images/RepresentingML.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras\n",
    "\n",
    "Keras is a model-level library, providing high-level building blocks for developing deep learning models. It does not handle low-level operations such as tensor products, convolutions and so on itself. \n",
    "<img src=\"https://keras.io/img/keras-logo-small.jpg\" width=\"140\">\n",
    "\n",
    "Keras development is backed primarily by Google, and the Keras API comes packaged in TensorFlow as tf.keras. Additionally, Microsoft maintains the CNTK Keras backend. Amazon AWS is maintaining the Keras fork with MXNet support. Other contributing companies include NVIDIA, Uber, and Apple (with CoreML).\n",
    "\n",
    "<img src=\"./images/KerasStack.png\">\n",
    "\n",
    "\n",
    "## Keras backend\n",
    "Keras relies on a specialized, well optimized tensor manipulation library to do so, serving as the \"backend engine\" of Keras. Rather than picking one single tensor library and making the implementation of Keras tied to that library, Keras handles the problem in a modular way, and several different backend engines can be plugged seamlessly into Keras.\n",
    "\n",
    "At this time, Keras has three backend implementations available: the TensorFlow backend, the Theano backend, and the CNTK backend.\n",
    "\n",
    "* [TensorFlow](https://www.tensorflow.org/lite) is an open-source symbolic tensor manipulation framework developed by Google.\n",
    "* [Theano](http://deeplearning.net/software/theano/) is an open-source symbolic tensor manipulation framework developed by LISA Lab at Université de Montréal.Theano is a Python library that allows you to define, optimize, and evaluate mathematical expressions involving multi-dimensional arrays efficiently. The latest release of Theano was on 2017/11/15. \n",
    "* [CNTK](https://docs.microsoft.com/en-us/cognitive-toolkit/) is an open-source toolkit for deep learning developed by Microsoft. It describes neural networks as a series of computational steps via a directed graph. CNTK allows the user to easily realize and combine popular model types such as feed-forward DNNs, convolutional neural networks (CNNs) and recurrent neural networks (RNNs/LSTMs). CNTK implements stochastic gradient descent (SGD, error backpropagation) learning with automatic differentiation and parallelization across multiple GPUs and servers.<br><br><br><br>\n",
    "\n",
    "\n",
    "## Keras popularity\n",
    "\n",
    "<img src=\"./images/KerasPop01.png\" width=\"600\">\n",
    "<br><br>\n",
    "<img src=\"./images/KerasPop02.png\" width=\"600\">\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Keras Ecosystem\n",
    "\n",
    "* ### [Keras Tuner](https://keras-team.github.io/keras-tuner/)\n",
    "scalable hyperparameter search framework\n",
    "* ### [AutoKeras](https://autokeras.com/)\n",
    "widely accessible and easy to learn and use machine learning AutoML system based on Keras\n",
    "* ### [TensorFlow Cloud](https://github.com/tensorflow/cloud)\n",
    "set of utilities for running large-scale Keras training jobs on Google Cloud Platform\n",
    "* ### [TensorFlow.js](https://www.tensorflow.org/js)\n",
    "used for running TF models in the browser or on a Node.js server\n",
    "* ### [TensorFlow Lite](https://www.tensorflow.org/lite) \n",
    "open source deep learning framework for deploying ML models on mobile and IoT devices\n",
    "* ### [Model optimization toolkit](https://www.tensorflow.org/model_optimization)\n",
    "toolkit is used to make ML models faster and more memory and power efficient\n",
    "* ### [TFX integration](https://www.tensorflow.org/tfx) \n",
    "ML platform for deploying and maintaining production machine learning pipelines\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Interoperability and Compatibility\n",
    "Keras also supports the [ONNX](https://onnx.ai/) format. \n",
    "\n",
    "<img src=\"https://onnx.ai/assets/mlogo.png\" width=\"140\">\n",
    "\n",
    "ONNX is a open format to represent deep learning models. With ONNX, AI developers can more easily move models between state-of-the-art tools and choose the combination that is best for them. ONNX is developed and supported by a community of partners.\n",
    "\n",
    "<img src=\"./images/ONNXCommunity.png\">\n",
    "\n",
    "The keras2onnx model converter enables users to convert Keras models into the ONNX model format. Initially, the Keras converter was developed in the project onnxmltools. To support more kinds of Keras models and reduce the complexity of mixing multiple converters, keras2onnx was created to convert the Keras model only.\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# End to end ML model requirements\n",
    "\n",
    "#### 1. Acquiring/Creating a dataset \n",
    "#### 2. Preparing a dataset\n",
    "#### 3. Dataset split to train and test data\n",
    "#### 4. Training the ML model\n",
    "#### 5. The ML model validation\n",
    "#### 6. ML deployment\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. [CIFAR-10/100](https://www.cs.toronto.edu/~kriz/cifar.html) dataset\n",
    "Dataset consists of 60000 32x32 colour images in 10 classes, with 6000 images per class. There are 50000 training images and 10000 test images. \n",
    "<img src=\"./images/CIFAR.png\" width=\"500\">\n",
    "\n",
    "### 2. [MNIST](http://yann.lecun.com/exdb/mnist/) Dataset\n",
    "The MNIST database has a training set of 60,000 examples, and a test set of 10,000 examples. \n",
    "<img src=\"./images/MNIST.png\" width=\"500\">\n",
    "\n",
    "### 3. IMDB-Wiki Dataset\n",
    "Dataset has 520k images - gender and age prediction.\n",
    "<img src=\"./images/IMDB.png\" width=\"500\">\n",
    "\n",
    "### 4. [ImageNet](http://www.image-net.org/challenges/LSVRC/) dataset\n",
    "Evaluation of object detection and image classification algorithms.\n",
    "<img src=\"./images/imagenet.jpeg\" width=\"500\">\n",
    "\n",
    "### 5. Places2 Database dataset\n",
    "Dateaset has more than 10 million images and over 400 scenes. It is used for scene classification and scene parsing.\n",
    "<img src=\"./images/Places.png\" width=\"500\">\n",
    "\n",
    "### 6. [COCO](http://cocodataset.org/#external) dataset\n",
    "A large-scale object detection, segmentation, and captioning dataset with several features including Object segmentation, Recognition in context, Superpixel stuff segmentation, 330K images (>200K labeled), 1.5 million object instances, 80 object categories, 91 stuff categories, 5 captions per image, 250,000 people with keypoints.\n",
    "<img src=\"./images/COCO.png\" width=\"500\">\n",
    "\n",
    "### 7. [Kaggle Datasets Collection](https://www.kaggle.com/datasets) \n",
    "Kaggle enables you to search among 36924 datasets. \n",
    "<img src=\"./images/KaggleData.png\" width=\"500\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Acquiring Datasets using MS Azure Bing Search API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install using pip install azure-cognitiveservices-search-imagesearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-search-imagesearch in c:\\programdata\\anaconda3\\lib\\site-packages (2.0.0)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-search-imagesearch) (1.1.20)\n",
      "Requirement already satisfied: msrest>=0.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-search-imagesearch) (0.6.6)\n",
      "Requirement already satisfied: msrestazure<2.0.0,>=0.4.32 in c:\\programdata\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-search-imagesearch) (0.6.3)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (2.22.0)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (0.6.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (2020.4.5.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (1.2.0)\n",
      "Requirement already satisfied: adal<2.0.0,>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from msrestazure<2.0.0,>=0.4.32->azure-cognitiveservices-search-imagesearch) (1.2.3)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (3.0.4)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (2.8)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (1.25.7)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (1.13.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-search-imagesearch) (3.0.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from adal<2.0.0,>=0.6.0->msrestazure<2.0.0,>=0.4.32->azure-cognitiveservices-search-imagesearch) (2.8.1)\n",
      "Requirement already satisfied: cryptography>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from adal<2.0.0,>=0.6.0->msrestazure<2.0.0,>=0.4.32->azure-cognitiveservices-search-imagesearch) (2.8)\n",
      "Requirement already satisfied: PyJWT>=1.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from adal<2.0.0,>=0.6.0->msrestazure<2.0.0,>=0.4.32->azure-cognitiveservices-search-imagesearch) (1.7.1)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\programdata\\anaconda3\\lib\\site-packages (from cryptography>=1.1.0->adal<2.0.0,>=0.6.0->msrestazure<2.0.0,>=0.4.32->azure-cognitiveservices-search-imagesearch) (1.13.2)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography>=1.1.0->adal<2.0.0,>=0.6.0->msrestazure<2.0.0,>=0.4.32->azure-cognitiveservices-search-imagesearch) (2.19)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure-cognitiveservices-search-imagesearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: azure-cognitiveservices-search-visualsearch in c:\\programdata\\anaconda3\\lib\\site-packages (0.2.0)\n",
      "Requirement already satisfied: msrest>=0.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-search-visualsearch) (0.6.6)\n",
      "Requirement already satisfied: azure-common~=1.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from azure-cognitiveservices-search-visualsearch) (1.1.20)\n",
      "Requirement already satisfied: requests~=2.16 in c:\\programdata\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-search-visualsearch) (2.22.0)\n",
      "Requirement already satisfied: isodate>=0.6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-search-visualsearch) (0.6.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-search-visualsearch) (1.2.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from msrest>=0.5.0->azure-cognitiveservices-search-visualsearch) (2020.4.5.1)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-search-visualsearch) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-search-visualsearch) (1.25.7)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests~=2.16->msrest>=0.5.0->azure-cognitiveservices-search-visualsearch) (2.8)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from isodate>=0.6.0->msrest>=0.5.0->azure-cognitiveservices-search-visualsearch) (1.13.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests-oauthlib>=0.5.0->msrest>=0.5.0->azure-cognitiveservices-search-visualsearch) (3.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install azure-cognitiveservices-search-visualsearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.search.imagesearch import ImageSearchClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "import requests\n",
    "from requests import exceptions\n",
    "import cv2\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create variables for your subscription key and search term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "subscription_key = '54806723b7f74ade99010c3cc6c2602b'\n",
    "subscription_endpoint = 'https://api.cognitive.microsoft.com/bing/v7.0/images/search'\n",
    "max_images=100\n",
    "group_size=20\n",
    "search_term = \"car\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "# when attempting to download images from the web both the Python programming language and the requests library have a number of\n",
    "# exceptions that can be thrown so let's build a list of them now so we can filter on them\n",
    "EXCEPTIONS = set([IOError, FileNotFoundError,exceptions.RequestException, exceptions.HTTPError, exceptions.ConnectionError, exceptions.Timeout])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the search term in a convenience variable then set the headers and search parameters\n",
    "term = search_term\n",
    "headers = {\"Ocp-Apim-Subscription-Key\" : subscription_key}\n",
    "params = {\"q\": term, \"offset\": 0, \"count\": group_size}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching Bing API for 'car'\n"
     ]
    }
   ],
   "source": [
    "# make the search\n",
    "print(\"Searching Bing API for '{}'\".format(term))\n",
    "search = requests.get(subscription_endpoint, headers=headers, params=params)\n",
    "search.raise_for_status()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 100 search results for 'car'\n"
     ]
    }
   ],
   "source": [
    "# grab the results from the search, including the total number of\n",
    "# estimated results returned by the Bing API\n",
    "results = search.json()\n",
    "estNumResults = min(results[\"totalEstimatedMatches\"], max_images)\n",
    "print(\"There are {} search results for '{}'\".format(estNumResults,term))\n",
    "# initialize the total number of images downloaded thus far\n",
    "total = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Making request for group 0-20 of 100...\n",
      "Making request for group 20-40 of 100...\n",
      "Making request for group 40-60 of 100...\n",
      "Making request for group 60-80 of 100...\n",
      "Making request for group 80-100 of 100...\n"
     ]
    }
   ],
   "source": [
    "# loop over the estimated number of results in `group_size` groups\n",
    "for offset in range(0, estNumResults, group_size):\n",
    "\n",
    "    # update the search parameters using the current offset, then make the request to fetch the results\n",
    "    print(\"Making request for group {}-{} of {}...\".format(\n",
    "    offset, offset + group_size, estNumResults))\n",
    "    params[\"offset\"] = offset\n",
    "    search = requests.get(subscription_endpoint, headers=headers, params=params)\n",
    "    search.raise_for_status()\n",
    "    results = search.json()\n",
    "    #print(results)\n",
    "    #print(\"Saving images for group {}-{} of {}...\".format(offset, offset + group_size, estNumResults))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Folder exist\n"
     ]
    }
   ],
   "source": [
    "ROOT_DIR=os.getcwd()\n",
    "output_dir=os.path.join(ROOT_DIR,search_term)\n",
    "if not os.path.exists(output_dir):\n",
    "    os.mkdir(output_dir)\n",
    "print('Folder exist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image fetching: https://s3.caradvice.com.au/wp-content/uploads/2016/01/2016-citroen-ds5-hatch-46.jpg\n",
      "https://s3.caradvice.com.au/wp-content/uploads/2016/01/2016-citroen-ds5-hatch-46.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000000.jpg\n",
      "Image fetching: https://car-images.bauersecure.com/pagefiles/83941/skoda_fabia_review_1.jpg\n",
      "https://car-images.bauersecure.com/pagefiles/83941/skoda_fabia_review_1.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000001.jpg\n",
      "Image fetching: https://s3.caradvice.com.au/wp-content/uploads/2010/05/Renault-Zoe-2.jpg\n",
      "https://s3.caradvice.com.au/wp-content/uploads/2010/05/Renault-Zoe-2.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000002.jpg\n",
      "Image fetching: https://s3.caradvice.com.au/wp-content/uploads/2012/04/Mazda-RX-8-rear-driving.jpg\n",
      "https://s3.caradvice.com.au/wp-content/uploads/2012/04/Mazda-RX-8-rear-driving.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000003.jpg\n",
      "Image fetching: https://s3.caradvice.com.au/wp-content/uploads/2015/09/2015-automotive-photography-tips-howto-1-2.jpg\n",
      "https://s3.caradvice.com.au/wp-content/uploads/2015/09/2015-automotive-photography-tips-howto-1-2.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000004.jpg\n",
      "Image fetching: https://wallpapersite.com/images/wallpapers/bugatti-veyron-grand-sport-vitesse-1080x1920-sports-car-hd-5k-3360.jpg\n",
      "https://wallpapersite.com/images/wallpapers/bugatti-veyron-grand-sport-vitesse-1080x1920-sports-car-hd-5k-3360.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000005.jpg\n",
      "Image fetching: https://car-images.bauersecure.com/pagefiles/76837/1752x1168/top10_design_fails_03.jpg?mode=max&quality=90&scale=down\n",
      "https://car-images.bauersecure.com/pagefiles/76837/1752x1168/top10_design_fails_03.jpg?mode=max&quality=90&scale=down\n",
      "C:\\pyproject\\cvlab\\car\\00000006.jpg?mode=max&quality=90&scale=down\n",
      "[INFO] skipping: https://car-images.bauersecure.com/pagefiles/76837/1752x1168/top10_design_fails_03.jpg?mode=max&quality=90&scale=down\n",
      "Image fetching: http://s3.caradvice.com.au/wp-content/uploads/2012/06/kia-sorento-platinum-8.jpg\n",
      "http://s3.caradvice.com.au/wp-content/uploads/2012/06/kia-sorento-platinum-8.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000006.jpg\n",
      "Image fetching: https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Ford_Cirrus_5.jpg/1200px-Ford_Cirrus_5.jpg\n",
      "https://upload.wikimedia.org/wikipedia/commons/thumb/1/12/Ford_Cirrus_5.jpg/1200px-Ford_Cirrus_5.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000007.jpg\n",
      "Image fetching: https://s3.caradvice.com.au/wp-content/uploads/2015/05/15Camry_51.jpg\n",
      "https://s3.caradvice.com.au/wp-content/uploads/2015/05/15Camry_51.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000008.jpg\n",
      "Image fetching: https://car-images.bauersecure.com/pagefiles/81082/audi-flying-car-19.jpg\n",
      "https://car-images.bauersecure.com/pagefiles/81082/audi-flying-car-19.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000009.jpg\n",
      "Image fetching: https://2.bp.blogspot.com/-CuoffxmNu-I/UZno9oAVm7I/AAAAAAAAB1s/-sx4AoecYys/s1600/Bentley-Continental-GT3-concept-01.jpg\n",
      "https://2.bp.blogspot.com/-CuoffxmNu-I/UZno9oAVm7I/AAAAAAAAB1s/-sx4AoecYys/s1600/Bentley-Continental-GT3-concept-01.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000010.jpg\n",
      "Image fetching: https://s3.caradvice.com.au/wp-content/uploads/2016/11/2017-Ford-Fiesta-unveiled-at-GoFurther-event_4.jpg\n",
      "https://s3.caradvice.com.au/wp-content/uploads/2016/11/2017-Ford-Fiesta-unveiled-at-GoFurther-event_4.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000011.jpg\n",
      "Image fetching: https://natsukashigarage.files.wordpress.com/2014/01/eat-sleep-meet-121.jpeg\n",
      "https://natsukashigarage.files.wordpress.com/2014/01/eat-sleep-meet-121.jpeg\n",
      "C:\\pyproject\\cvlab\\car\\00000012.jpeg\n",
      "Image fetching: http://s3.caradvice.com.au/wp-content/uploads/2010/02/2009_mg6.jpg\n",
      "http://s3.caradvice.com.au/wp-content/uploads/2010/02/2009_mg6.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000013.jpg\n",
      "Image fetching: https://car-pictures-download.com/wp-content/uploads/2019/03/Jaguar-F-Type-HD-sports-car-wallpaper-1920x1080.jpg\n",
      "https://car-pictures-download.com/wp-content/uploads/2019/03/Jaguar-F-Type-HD-sports-car-wallpaper-1920x1080.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000014.jpg\n",
      "Image fetching: https://s3.caradvice.com.au/wp-content/uploads/2011/07/Mazda_RX-7_2.jpg\n",
      "https://s3.caradvice.com.au/wp-content/uploads/2011/07/Mazda_RX-7_2.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000015.jpg\n",
      "Image fetching: http://s3.caradvice.com.au/wp-content/uploads/2015/07/Audi-TT-Roadster_11.jpg\n",
      "http://s3.caradvice.com.au/wp-content/uploads/2015/07/Audi-TT-Roadster_11.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000016.jpg\n",
      "Image fetching: https://www.automobilesreview.com/gallery/mattel-hot-wheels-darth-vader-car/mattel-hot-wheels-darth-vader-car-03.jpg\n",
      "https://www.automobilesreview.com/gallery/mattel-hot-wheels-darth-vader-car/mattel-hot-wheels-darth-vader-car-03.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000017.jpg\n",
      "Image fetching: https://www.zero2turbo.com/wp-content/uploads/2018/05/lamborghini-urus-pace-car-super-trofeo-7.jpg\n",
      "https://www.zero2turbo.com/wp-content/uploads/2018/05/lamborghini-urus-pace-car-super-trofeo-7.jpg\n",
      "C:\\pyproject\\cvlab\\car\\00000018.jpg\n"
     ]
    }
   ],
   "source": [
    "# loop over the results\n",
    "for v in results[\"value\"]:\n",
    "    # try to download the image\n",
    "    try:\n",
    "        # make a request to download the image\n",
    "        print(\"Image fetching: {}\".format(v[\"contentUrl\"]))\n",
    "        r = requests.get(v[\"contentUrl\"], timeout=30)\n",
    "        print(v[\"contentUrl\"])\n",
    "        \n",
    "        # build the path to the output image\n",
    "        ext = v[\"contentUrl\"][v[\"contentUrl\"].rfind(\".\"):]\n",
    "    \n",
    "        p = os.path.join(output_dir, \"{}{}\".format(str(total).zfill(8), ext))\n",
    "        print(p)\n",
    "        \n",
    "        # write the image to disk\n",
    "        f = open(p, \"wb\")\n",
    "        f.write(r.content)\n",
    "        f.close()\n",
    "        \n",
    "    # catch any errors that would not unable us to download the image\n",
    "    except Exception as e:\n",
    "        \n",
    "        # check to see if our exception is in our list of\n",
    "        # exceptions to check for\n",
    "        if type(e) in EXCEPTIONS:\n",
    "            print(\"[INFO] skipping: {}\".format(v[\"contentUrl\"]))\n",
    "            continue\n",
    "    # try to load the image from disk\n",
    "    image = cv2.imread(p)\n",
    "    # if the image is `None` then we could not properly load the\n",
    "    # image from disk (so it should be ignored)\n",
    "    if image is None:\n",
    "        print(\"[INFO] deleting: {}\".format(p))\n",
    "        os.remove(p)\n",
    "        continue\n",
    "    # update the counter\n",
    "    total += 1                            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "#### 1. Create two folders with two groups of images for classification purpose\n",
    "#### 2. Increase the number of downloadable images\n",
    "#### 3. How would you change the size of the images\n",
    "#### 4. How would you download only PNG images - would you change parameters/check with https://docs.microsoft.com/en-us/azure/cognitive-services/bing-image-search/quickstarts/python.\n",
    "\n",
    "\n",
    "<br><br><br><br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Datasets in Cloud environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is an example how image dataset was created within a cloud environment to detect objects in images. In this example GCP - [Google Cloud Platform Vision module](https://console.cloud.google.com/vision/datasets?project=tvdetection01) was used to upload, store, create, label, train, validate and export ML model to mobile, web or containerized platforms."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
